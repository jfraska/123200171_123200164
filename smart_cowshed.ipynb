{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "name": "smart_cowshed.ipynb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jfraska/123200171_123200164/blob/master/smart_cowshed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HK5tEzR_99Ga"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import os\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from skimage import io\n",
        "from PIL import Image\n",
        "import random\n",
        "from shutil import copyfile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get dataset\n",
        "os.environ['KAGGLE_USERNAME'] = \"alifianzulfaani\"\n",
        "os.environ['KAGGLE_KEY'] = \"4b8aa99d8f0cfab2b85c684ad6864489\"\n",
        "!kaggle datasets download -d alifianzulfaani/cowshed-data"
      ],
      "metadata": {
        "id": "Itx0-W2G-H82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8424483c-4d4a-4a46-e020-1dec189bc9ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading cowshed-data.zip to /content\n",
            "100% 26.0M/26.0M [00:01<00:00, 25.5MB/s]\n",
            "100% 26.0M/26.0M [00:01<00:00, 15.1MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aleep"
      ],
      "metadata": {
        "id": "i77ZjwqPZORL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract dataset\n",
        "from zipfile import ZipFile\n",
        "file_name = \"/content/cowshed-data.zip\"\n",
        "zp = ZipFile(file_name, 'r')\n",
        "zp.extractall(path='/content/')\n",
        "print('done')"
      ],
      "metadata": {
        "id": "odr7yls5-MCD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87f0b3cd-19d4-47c6-f074-c4dd57d5b4f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split folder\n",
        "!pip install split-folders\n",
        "import splitfolders\n",
        "\n",
        "splitfolders.ratio('/content/Dataset',\n",
        "                   output=\"/content/used-cowshed-data\", seed=1337, ratio=(0.7,0.2,0.1))"
      ],
      "metadata": {
        "id": "5ZyY2OmBQLg1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2232eee7-3eb0-4aa9-bfdc-aac819be69e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Copying files: 158 files [00:00, 1775.21 files/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the name of classes\n",
        "os.listdir('/content/used-cowshed-data/train')\n",
        "os.listdir('/content/used-cowshed-data/val')\n",
        "os.listdir('/content/used-cowshed-data/test')"
      ],
      "metadata": {
        "id": "wSN3kopT8aDg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf34c5ab-20cb-4ec4-8ae2-43386285ece6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['air_liur_sehat',\n",
              " 'kaki_sehat',\n",
              " 'gusi_sehat',\n",
              " 'air_liur_sakit',\n",
              " 'lidah_sakit',\n",
              " 'lidah_sehat',\n",
              " 'kaki_sakit',\n",
              " 'gusi_sakit']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the name of directory\n",
        "base_dir = '/content/used-cowshed-data'\n",
        "train_dir = os.path.join(base_dir, 'train/')\n",
        "val_dir = os.path.join(base_dir, 'val/')\n",
        "test_dir = os.path.join(base_dir, 'test/')\n",
        "\n",
        "train_aug_dir = os.path.join(base_dir, 'aug/')\n",
        "# val_aug = '/content/augmented/validation/'\n",
        "# test_aug = '/content/augmented/test/'\n",
        "print('done')"
      ],
      "metadata": {
        "id": "OkXoUluG5YFo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "374afde9-efe7-4b75-b27b-19c8d20ebddc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Image augmentation\n",
        "IMG_WIDTH = 150\n",
        "IMG_HEIGHT = 150\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=30,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    fill_mode='constant'\n",
        "    )\n",
        "\n",
        "def aug_img(input_dir, output_dir, nums):\n",
        "    itr_num = nums\n",
        "    itr = 0\n",
        "    for each_data in os.listdir(input_dir):\n",
        "        dataset = []\n",
        "        image_directory = input_dir+each_data+'/'\n",
        "        dataset = []\n",
        "\n",
        "        my_images = os.listdir(image_directory)\n",
        "        for i, image_name in enumerate(my_images):\n",
        "            if (image_name.split('.')[1] == 'jpg' or 'jpeg'):\n",
        "                image = io.imread(image_directory + image_name)\n",
        "                image = Image.fromarray(image, 'RGB')\n",
        "                image = image.resize((IMG_WIDTH,IMG_HEIGHT))\n",
        "                dataset.append(np.array(image))\n",
        "\n",
        "        x = np.array(dataset)\n",
        "        aug_dir = output_dir+each_data\n",
        "        os.makedirs(aug_dir)\n",
        "\n",
        "        i = 1\n",
        "        for batch in datagen.flow(x, batch_size=16, save_to_dir=aug_dir,\n",
        "                                  save_prefix='aug'+image_name,\n",
        "                                  save_format='png'):\n",
        "            i += 1\n",
        "            if i > itr_num[itr]:\n",
        "                break\n",
        "\n",
        "        itr +=1\n",
        "        print('images are: '.format(i)+str(len(os.listdir(aug_dir))))\n",
        "    print()\n",
        "\n",
        "num_train = [15, 13, 15, 10, 10, 10 ,10, 10]\n",
        "# num_val = [0,0,0,0]\n",
        "# num_test = [0,0,0,0]\n",
        "\n",
        "aug_img(train_dir, train_aug_dir, num_train)\n",
        "# aug_img(validation_dir, val_aug, num_val)\n",
        "# aug_img(test_dir, test_aug, num_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dIw6aOIfDhf",
        "outputId": "793454e0-010a-4e46-96c6-bcb89dbf654e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "images are: 163\n",
            "images are: 208\n",
            "images are: 105\n",
            "images are: 90\n",
            "images are: 99\n",
            "images are: 100\n",
            "images are: 120\n",
            "images are: 130\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Processing Data\n",
        "BATCH_SIZE = 32\n",
        "train_datagen = ImageDataGenerator(rescale=1. /255)\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        train_aug_dir,\n",
        "        target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical')\n",
        "\n",
        "validation_datagen = ImageDataGenerator(\n",
        "                    rescale=1./255)\n",
        "validation_generator = validation_datagen.flow_from_directory(\n",
        "        val_dir,\n",
        "        target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical')\n",
        "\n",
        "test_datagen = ImageDataGenerator(\n",
        "                    rescale=1./255)\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "        test_dir,\n",
        "        target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
        "        batch_size=BATCH_SIZE,\n",
        "        class_mode='categorical')"
      ],
      "metadata": {
        "id": "MKs6QqPt9RpG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c163a62-eda4-4297-f5b0-20c3e39f01f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1015 images belonging to 8 classes.\n",
            "Found 29 images belonging to 8 classes.\n",
            "Found 22 images belonging to 8 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count of training data after augmentation\n",
        "print(\"Total Data Augmentasi: \", sum([len(files) for r, d, files in os.walk('/content/used-cowshed-data/aug')]))\n",
        "print(\"Total Data Validasi: \", sum([len(files) for r, d, files in os.walk('/content/used-cowshed-data/val')]))"
      ],
      "metadata": {
        "id": "EmTpuu5L9mWZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ecc3519-f886-421c-fcce-1b3bbb140e7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Data Augmentasi:  1015\n",
            "Total Data Validasi:  29\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Index class\n",
        "test_generator.class_indices"
      ],
      "metadata": {
        "id": "ShyauR86F9go",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06386e21-b4c1-4357-f532-f1941612f01b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'air_liur_sakit': 0,\n",
              " 'air_liur_sehat': 1,\n",
              " 'gusi_sakit': 2,\n",
              " 'gusi_sehat': 3,\n",
              " 'kaki_sakit': 4,\n",
              " 'kaki_sehat': 5,\n",
              " 'lidah_sakit': 6,\n",
              " 'lidah_sehat': 7}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## EfficientNet versi B0"
      ],
      "metadata": {
        "id": "0zxnfAPAkY5C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U efficientnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x18D75P7kpAY",
        "outputId": "e9b24f7e-6cb4-4d88-974d-4f7c1fe82318"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting efficientnet\n",
            "  Downloading efficientnet-1.1.1-py3-none-any.whl (18 kB)\n",
            "Collecting keras-applications<=1.0.8,>=1.0.7 (from efficientnet)\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from efficientnet) (0.19.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.23.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (3.9.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (1.11.3)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (3.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (2.31.5)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (2023.9.26)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet) (23.2)\n",
            "Installing collected packages: keras-applications, efficientnet\n",
            "Successfully installed efficientnet-1.1.1 keras-applications-1.0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Activation, BatchNormalization, Conv2D, Dense, Dropout, Flatten, MaxPooling2D\n",
        "from tensorflow.keras.models import Model\n",
        "import efficientnet.keras as efn\n",
        "\n",
        "base_model = efn.EfficientNetB7(input_shape = (150, 150, 3), include_top = False, weights = 'imagenet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmW-k-41kYTb",
        "outputId": "055ea173-612b-45f4-8dcb-395abe19283c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://github.com/Callidior/keras-applications/releases/download/efficientnet/efficientnet-b7_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5\n",
            "258434480/258434480 [==============================] - 5s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in base_model.layers:\n",
        "    layer.trainable = False"
      ],
      "metadata": {
        "id": "JKUAynjCk4rD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(1024, activation=\"relu\")(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "# Add a final softmax layer with 8 node for classification output\n",
        "predictions = Dense(8, activation=\"softmax\")(x)\n",
        "model_final = Model(inputs = base_model.input, outputs = predictions)"
      ],
      "metadata": {
        "id": "K6YQ2odxk7V7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_final.compile(tf.keras.optimizers.legacy.RMSprop(learning_rate=0.0001, decay=1e-6),loss='categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "FM5ysX9hk-MF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use of callbacks to prevents overfitting and stops training once accuracy is met\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('val_loss') < 0.1):\n",
        "      print(\"\\nLoss di bawah 10%, hentikan training!\")\n",
        "      self.model.stop_training = True\n",
        "\n",
        "callbacks = myCallback()"
      ],
      "metadata": {
        "id": "bLEJyMt5pQ95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eff_history = model_final.fit_generator(train_generator, validation_data = validation_generator, steps_per_epoch = 32, epochs = 10, callbacks=[callbacks])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8jSkfU8lESV",
        "outputId": "9c1fa4fe-f30c-4731-84f2-2a7d73d204e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "32/32 [==============================] - 358s 10s/step - loss: 2.5471 - accuracy: 0.5034 - val_loss: 1.2869 - val_accuracy: 0.7586\n",
            "Epoch 2/10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluasi Metrik"
      ],
      "metadata": {
        "id": "svnGsIe7k--Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss train & validation\n",
        "plt.plot(eff_history.history['loss'], label='Training Loss')\n",
        "plt.plot(eff_history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Loss Plot')\n",
        "plt.ylabel('Value')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(loc=\"upper right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YmNQ79PjIUJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy train & validation\n",
        "plt.plot(eff_history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(eff_history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Accuracy Plot')\n",
        "plt.ylabel('Value')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zbOfzLxZJJAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "%matplotlib inline\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "\n",
        "  # predicting images\n",
        "  path = fn\n",
        "  img = image.load_img(path, target_size=(150,150))\n",
        "\n",
        "  imgplot = plt.imshow(img)\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "  images = np.vstack([x])\n",
        "\n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  output_class = np.argmax(classes)\n",
        "  print(fn)\n",
        "  if output_class==0:\n",
        "      print('air_liur_sakit')\n",
        "  elif output_class==1:\n",
        "      print('air_liur_sehat')\n",
        "  elif output_class==2:\n",
        "      print('gusi_sakit')\n",
        "  elif output_class==3:\n",
        "      print('gusi_sehat')\n",
        "  elif output_class==4:\n",
        "      print('kaki_sakit')\n",
        "  elif output_class==5:\n",
        "      print('kaki_sehat')\n",
        "  elif output_class==6:\n",
        "      print('lidah_sakit')\n",
        "  elif output_class==7:\n",
        "      print('lidah_sehat')"
      ],
      "metadata": {
        "id": "dxsUvOFoK3pU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}